{
 "cells": [
  {
   "cell_type": "code",
   "id": "07eeec41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T17:21:02.538754Z",
     "start_time": "2025-09-12T17:21:02.294424Z"
    }
   },
   "source": [
    "# Kh·ªüi t·∫°o Spark Session v·ªõi c√°c c·∫•u h√¨nh c·∫ßn thi·∫øt\n",
    "import pyspark, os, shutil, sys\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "os.environ['JAVA_TOOL_OPTIONS'] = '--add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED'\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/homebrew/Cellar/apache-spark/4.0.0/libexec\"\n",
    "os.environ[\"PATH\"] = os.path.join(os.environ[\"SPARK_HOME\"], \"bin\") + \":\" + os.environ[\"PATH\"]\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DrugPipeline\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Djava.security.manager=allow\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-Djava.security.manager=allow\") \\\n",
    "    .config(\"spark.sql.execution.pyspark.udf.faulthandler.enabled\", \"true\") \\\n",
    "    .config(\"spark.python.worker.faulthandler.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Kh·ªüi t·∫°o Spark Session v·ªõi c√°c c·∫•u h√¨nh c·∫ßn thi·∫øt\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpyspark\u001B[39;00m,\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m,\u001B[38;5;250m \u001B[39m\u001B[34;01mshutil\u001B[39;00m,\u001B[38;5;250m \u001B[39m\u001B[34;01msys\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpyspark\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msql\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SparkSession\n\u001B[32m      5\u001B[39m os.environ[\u001B[33m'\u001B[39m\u001B[33mJAVA_TOOL_OPTIONS\u001B[39m\u001B[33m'\u001B[39m] = \u001B[33m'\u001B[39m\u001B[33m--add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED\u001B[39m\u001B[33m'\u001B[39m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'pyspark'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "4021c047",
   "metadata": {},
   "source": [
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV\n",
    "df = spark.read.csv(\"data/Medicine_Details.csv\", header=True, inferSchema=True)\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca1c8ef3",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import col, lower, concat_ws, udf\n",
    "\n",
    "columns = df.columns\n",
    "df_clean = df\n",
    "if \"Composition\" in columns:\n",
    "    df_clean = df_clean.withColumn(\"composition_clean\", lower(col(\"Composition\")))\n",
    "if \"Uses\" in columns:\n",
    "    df_clean = df_clean.withColumn(\"uses_clean\", lower(col(\"Uses\")))\n",
    "if \"Side_effects\" in columns:\n",
    "    df_clean = df_clean.withColumn(\"side_effects_clean\", lower(col(\"Side_effects\")))\n",
    "\n",
    "# T·∫°o vƒÉn b·∫£n ƒë·ªÉ nh√∫ng s·ª≠ d·ª•ng c√°c c·ªôt c√≥ s·∫µn\n",
    "text_cols = []\n",
    "if \"composition_clean\" in df_clean.columns:\n",
    "    text_cols.append(col(\"composition_clean\"))\n",
    "if \"uses_clean\" in df_clean.columns:\n",
    "    text_cols.append(col(\"uses_clean\"))\n",
    "if \"side_effects_clean\" in df_clean.columns:\n",
    "    text_cols.append(col(\"side_effects_clean\"))\n",
    "    \n",
    "df_clean = df_clean.withColumn(\"text_for_embedding\", concat_ws(\" \", *text_cols))\n",
    "df_clean.show(5, truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f64b6d16",
   "metadata": {},
   "source": [
    "# S·ª≠ d·ª•ng m√¥ h√¨nh t·ª´ th∆∞ vi·ªán sentence-transformers ƒë·ªÉ t·∫°o h√†m UDF nh√∫ng vƒÉn b·∫£n\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "\n",
    "# model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "_model = None\n",
    "\n",
    "def embed_text(text):\n",
    "    global _model\n",
    "    if _model is None:\n",
    "        # √âp d√πng CPU ƒë·ªÉ tr√°nh crash MPS\n",
    "        _model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "    if text is None or text.strip() == \"\":\n",
    "        return [0.0] * 384\n",
    "    vec = _model.encode(text)\n",
    "    return vec.tolist()\n",
    "\n",
    "embed_udf = udf(embed_text, ArrayType(FloatType()))\n",
    "df_with_embeddings = df_clean.withColumn(\"embedding\", embed_udf(col(\"text_for_embedding\")))\n",
    "df_with_embeddings.select(\"Medicine Name\", \"embedding\").show(5, truncate=False)\n",
    "df_with_embeddings.write.mode(\"overwrite\").parquet(\"processed_drugs.parquet\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b15bb380",
   "metadata": {},
   "source": [
    "# ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7h5qdtpuo7",
   "metadata": {},
   "source": [
    "# ChromaDB Integration Setup\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def setup_chromadb_client(persist_directory: str = \"./chroma_db\"):\n",
    "    \"\"\"Setup ChromaDB client with persistent storage\"\"\"\n",
    "    client = chromadb.PersistentClient(path=persist_directory)\n",
    "    return client\n",
    "\n",
    "def create_collections(client):\n",
    "    \"\"\"Create all necessary collections\"\"\"\n",
    "    collections = {}\n",
    "    \n",
    "    # Main drugs collection for general semantic search\n",
    "    collections['drugs_main'] = client.get_or_create_collection(\n",
    "        name=\"drugs_main\",\n",
    "        metadata={\"hnsw:space\": \"cosine\", \"description\": \"Main drugs collection for semantic search\"}\n",
    "    )\n",
    "    \n",
    "    # Side effects specific collection\n",
    "    collections['drugs_side_effects'] = client.get_or_create_collection(\n",
    "        name=\"drugs_side_effects\", \n",
    "        metadata={\"hnsw:space\": \"cosine\", \"description\": \"Side effects analysis\"}\n",
    "    )\n",
    "    \n",
    "    # Composition specific collection\n",
    "    collections['drugs_composition'] = client.get_or_create_collection(\n",
    "        name=\"drugs_composition\",\n",
    "        metadata={\"hnsw:space\": \"cosine\", \"description\": \"Chemical composition similarity\"}\n",
    "    )\n",
    "    \n",
    "    # Reviews collection\n",
    "    collections['drugs_reviews'] = client.get_or_create_collection(\n",
    "        name=\"drugs_reviews\",\n",
    "        metadata={\"hnsw:space\": \"cosine\", \"description\": \"Review analytics\"}\n",
    "    )\n",
    "    \n",
    "    return collections\n",
    "\n",
    "client = setup_chromadb_client()\n",
    "collections = create_collections(client)\n",
    "print(\"ChromaDB setup functions loaded successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cf9409a5",
   "metadata": {},
   "source": [
    "df_with_embeddings = spark.read.parquet(\"processed_drugs.parquet\")\n",
    "\n",
    "print(\"Loaded DataFrame schema:\")\n",
    "df_with_embeddings.printSchema()\n",
    "\n",
    "print(f\"Total medicines loaded: {df_with_embeddings.count()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cu0ac3hug5s",
   "metadata": {},
   "source": [
    "# Data Transformation Functions\n",
    "def spark_df_to_chromadb_format(df_with_embeddings):\n",
    "    \"\"\"Convert Spark DataFrame with embeddings to ChromaDB format\"\"\"\n",
    "    \n",
    "    # Collect data from Spark DataFrame\n",
    "    print(\"Collecting data from Spark DataFrame...\")\n",
    "    medicines_data = df_with_embeddings.collect()\n",
    "    \n",
    "    # Prepare data for different collections\n",
    "    main_data = {\n",
    "        'ids': [],\n",
    "        'embeddings': [],\n",
    "        'metadatas': [],\n",
    "        'documents': []\n",
    "    }\n",
    "    \n",
    "    side_effects_data = {\n",
    "        'ids': [],\n",
    "        'embeddings': [],\n",
    "        'metadatas': [],\n",
    "        'documents': []\n",
    "    }\n",
    "    \n",
    "    composition_data = {\n",
    "        'ids': [],\n",
    "        'embeddings': [],\n",
    "        'metadatas': [],\n",
    "        'documents': []\n",
    "    }\n",
    "    \n",
    "    reviews_data = {\n",
    "        'ids': [],\n",
    "        'metadatas': []\n",
    "    }\n",
    "    \n",
    "    print(f\"Processing {len(medicines_data)} medicines...\")\n",
    "    \n",
    "    for i, row in enumerate(medicines_data):\n",
    "        medicine_id = f\"medicine_{i:06d}\"\n",
    "        \n",
    "        # Main collection data\n",
    "        main_data['ids'].append(medicine_id)\n",
    "        main_data['embeddings'].append(row[\"embedding\"])\n",
    "        main_data['documents'].append(row[\"text_for_embedding\"])\n",
    "        main_data['metadatas'].append({\n",
    "            \"medicine_name\": row[\"Medicine Name\"] or \"\",\n",
    "            \"composition\": row[\"Composition\"] or \"\",\n",
    "            \"uses\": row[\"Uses\"] or \"\",\n",
    "            \"side_effects\": row[\"Side_effects\"] or \"\",\n",
    "            \"manufacturer\": row[\"Manufacturer\"] or \"\",\n",
    "            \"excellent_review\": row[\"Excellent Review %\"] or 0,\n",
    "            \"average_review\": row[\"Average Review %\"] or 0,\n",
    "            \"poor_review\": row[\"Poor Review %\"] or 0,\n",
    "            \"image_url\": row[\"Image URL\"] or \"\"\n",
    "        })\n",
    "        \n",
    "        # Side effects collection\n",
    "        if row[\"Side_effects\"] and row[\"Side_effects\"].strip():\n",
    "            side_effects_data['ids'].append(f\"side_effects_{i:06d}\")\n",
    "            side_effects_data['embeddings'].append(row[\"embedding\"])\n",
    "            side_effects_data['documents'].append(row[\"Side_effects\"])\n",
    "            side_effects_data['metadatas'].append({\n",
    "                \"medicine_name\": row[\"Medicine Name\"] or \"\",\n",
    "                \"composition\": row[\"Composition\"] or \"\",\n",
    "                \"manufacturer\": row[\"Manufacturer\"] or \"\"\n",
    "            })\n",
    "        \n",
    "        # Composition collection\n",
    "        if row[\"Composition\"] and row[\"Composition\"].strip():\n",
    "            composition_data['ids'].append(f\"composition_{i:06d}\")\n",
    "            composition_data['embeddings'].append(row[\"embedding\"])\n",
    "            composition_data['documents'].append(row[\"Composition\"])\n",
    "            composition_data['metadatas'].append({\n",
    "                \"medicine_name\": row[\"Medicine Name\"] or \"\",\n",
    "                \"manufacturer\": row[\"Manufacturer\"] or \"\",\n",
    "                \"uses\": row[\"Uses\"] or \"\"\n",
    "            })\n",
    "        \n",
    "        # Reviews collection\n",
    "        reviews_data['ids'].append(f\"review_{i:06d}\")\n",
    "        reviews_data['metadatas'].append({\n",
    "            \"medicine_name\": row[\"Medicine Name\"] or \"\",\n",
    "            \"excellent_review\": row[\"Excellent Review %\"] or 0,\n",
    "            \"average_review\": row[\"Average Review %\"] or 0,\n",
    "            \"poor_review\": row[\"Poor Review %\"] or 0,\n",
    "            \"total_score\": (row[\"Excellent Review %\"] or 0) * 3 + (row[\"Average Review %\"] or 0) * 2 + (row[\"Poor Review %\"] or 0) * 1\n",
    "        })\n",
    "    \n",
    "    print(f\"Data transformation completed:\")\n",
    "    print(f\"- Main collection: {len(main_data['ids'])} items\")\n",
    "    print(f\"- Side effects collection: {len(side_effects_data['ids'])} items\") \n",
    "    print(f\"- Composition collection: {len(composition_data['ids'])} items\")\n",
    "    print(f\"- Reviews collection: {len(reviews_data['ids'])} items\")\n",
    "    \n",
    "    return main_data, side_effects_data, composition_data, reviews_data\n",
    "\n",
    "main_data, side_effects_data, composition_data, reviews_data = spark_df_to_chromadb_format(df_with_embeddings)\n",
    "\n",
    "print(\"Data transformation functions loaded successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "hdncgdd4s2f",
   "metadata": {},
   "source": [
    "# Batch Insert Functions\n",
    "def batch_insert_to_collection(collection, data, batch_size=1000):\n",
    "    \"\"\"Insert data to ChromaDB collection in batches\"\"\"\n",
    "    \n",
    "    total_items = len(data['ids'])\n",
    "    \n",
    "    for i in range(0, total_items, batch_size):\n",
    "        end_idx = min(i + batch_size, total_items)\n",
    "        \n",
    "        batch_ids = data['ids'][i:end_idx]\n",
    "        batch_metadatas = data['metadatas'][i:end_idx]\n",
    "        \n",
    "        if 'embeddings' in data and data['embeddings']:\n",
    "            batch_embeddings = data['embeddings'][i:end_idx]\n",
    "            batch_documents = data['documents'][i:end_idx] if 'documents' in data else None\n",
    "            \n",
    "            collection.add(\n",
    "                ids=batch_ids,\n",
    "                embeddings=batch_embeddings,\n",
    "                metadatas=batch_metadatas,\n",
    "                documents=batch_documents\n",
    "            )\n",
    "        else:\n",
    "            # For collections without embeddings (like reviews)\n",
    "            collection.add(\n",
    "                ids=batch_ids,\n",
    "                metadatas=batch_metadatas,\n",
    "                documents=[\"Review summary only\"] * len(batch_ids)\n",
    "            )\n",
    "        \n",
    "        print(f\"  Inserted batch {i//batch_size + 1}/{(total_items-1)//batch_size + 1}\")\n",
    "\n",
    "def populate_all_collections(collections, main_data, side_effects_data, composition_data, reviews_data):\n",
    "    \"\"\"Populate all ChromaDB collections with data\"\"\"\n",
    "    \n",
    "    print(\"Populating drugs_main collection...\")\n",
    "    batch_insert_to_collection(collections['drugs_main'], main_data)\n",
    "    \n",
    "    print(\"Populating drugs_side_effects collection...\")\n",
    "    batch_insert_to_collection(collections['drugs_side_effects'], side_effects_data)\n",
    "    \n",
    "    print(\"Populating drugs_composition collection...\")\n",
    "    batch_insert_to_collection(collections['drugs_composition'], composition_data)\n",
    "    \n",
    "    print(\"Populating drugs_reviews collection...\")\n",
    "    # Reviews collection doesn't need embeddings\n",
    "    reviews_data_simple = {\n",
    "        'ids': reviews_data['ids'],\n",
    "        'metadatas': reviews_data['metadatas']\n",
    "    }\n",
    "    batch_insert_to_collection(collections['drugs_reviews'], reviews_data_simple)\n",
    "    \n",
    "    print(\"All collections populated successfully!\")\n",
    "\n",
    "populate_all_collections(collections, main_data, side_effects_data, composition_data, reviews_data)\n",
    "\n",
    "print(\"Batch insert functions loaded successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dpbfbrfkcy4",
   "metadata": {},
   "source": [
    "# Query Interface Functions\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "\n",
    "def setup_query_model():\n",
    "    \"\"\"Setup the same model used for embeddings\"\"\"\n",
    "    return model  # Reuse the existing model\n",
    "\n",
    "def search_similar_medicines(collection, query_text, query_model, n_results=5):\n",
    "    \"\"\"Search for similar medicines based on query text\"\"\"\n",
    "    \n",
    "    # Generate embedding for query\n",
    "    query_embedding = query_model.encode(query_text).tolist()\n",
    "    \n",
    "    # Query the collection\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results,\n",
    "        include=[\"metadatas\", \"documents\", \"distances\"]\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def find_medicine_alternatives(collections, medicine_name, query_model, n_results=5):\n",
    "    \"\"\"Find alternative medicines based on composition similarity\"\"\"\n",
    "    \n",
    "    # First find the medicine in main collection\n",
    "    main_results = collections['drugs_main'].query(\n",
    "        query_texts=[medicine_name],\n",
    "        n_results=1,\n",
    "        include=[\"metadatas\"]\n",
    "    )\n",
    "    \n",
    "    if not main_results['metadatas'][0]:\n",
    "        return None\n",
    "    \n",
    "    composition = main_results['metadatas'][0][0]['composition']\n",
    "    \n",
    "    # Search in composition collection\n",
    "    alternatives = search_similar_medicines(\n",
    "        collections['drugs_composition'], \n",
    "        composition, \n",
    "        query_model, \n",
    "        n_results\n",
    "    )\n",
    "    \n",
    "    return alternatives\n",
    "\n",
    "def analyze_side_effects_similarity(collections, side_effect_query, query_model, n_results=10):\n",
    "    \"\"\"Find medicines with similar side effects\"\"\"\n",
    "    \n",
    "    results = search_similar_medicines(\n",
    "        collections['drugs_side_effects'],\n",
    "        side_effect_query,\n",
    "        query_model,\n",
    "        n_results\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_top_reviewed_medicines(collections, n_results=10):\n",
    "    \"\"\"Get top reviewed medicines\"\"\"\n",
    "    \n",
    "    # Get all reviews\n",
    "    all_reviews = collections['drugs_reviews'].get(include=[\"metadatas\"])\n",
    "    \n",
    "    # Sort by total_score in application layer\n",
    "    sorted_medicines = sorted(\n",
    "        zip(all_reviews['ids'], all_reviews['metadatas']),\n",
    "        key=lambda x: x[1]['total_score'],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    return sorted_medicines[:n_results]\n",
    "\n",
    "query_model = setup_query_model()\n",
    "print(\"Query functions loaded successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "elbum3xmw1g",
   "metadata": {},
   "source": [
    "# Demo Queries - Test ChromaDB Integration\n",
    "def demo_queries(collections, query_model):\n",
    "    \"\"\"Demonstrate various query capabilities\"\"\"\n",
    "    \n",
    "    print(\"\\n=== ChromaDB Query Demo ===\")\n",
    "    \n",
    "    # 1. Search for pain relief medicines\n",
    "    print(\"\\n1. üîç Searching for pain relief medicines:\")\n",
    "    pain_results = search_similar_medicines(\n",
    "        collections['drugs_main'], \n",
    "        \"pain relief headache fever\", \n",
    "        query_model, \n",
    "        3\n",
    "    )\n",
    "    for i, metadata in enumerate(pain_results['metadatas'][0]):\n",
    "        distance = pain_results['distances'][0][i]\n",
    "        print(f\"   {i+1}. {metadata['medicine_name']} (similarity: {1-distance:.3f})\")\n",
    "        print(f\"      Uses: {metadata['uses'][:100]}...\")\n",
    "        print(f\"      Manufacturer: {metadata['manufacturer']}\")\n",
    "        print()\n",
    "    \n",
    "    # 2. Find alternatives for a specific medicine\n",
    "    print(\"\\n2. üíä Finding alternatives for Paracetamol-like medicines:\")\n",
    "    alternatives = find_medicine_alternatives(\n",
    "        collections, \n",
    "        \"paracetamol acetaminophen\", \n",
    "        query_model, \n",
    "        3\n",
    "    )\n",
    "    if alternatives:\n",
    "        for i, metadata in enumerate(alternatives['metadatas'][0]):\n",
    "            distance = alternatives['distances'][0][i]\n",
    "            print(f\"   {i+1}. {metadata['medicine_name']} (similarity: {1-distance:.3f})\")\n",
    "            print(f\"      Composition: {metadata['composition']}\")\n",
    "            print(f\"      Manufacturer: {metadata['manufacturer']}\")\n",
    "            print()\n",
    "    \n",
    "    # 3. Analyze side effects\n",
    "    print(\"\\n3. ‚ö†Ô∏è Medicines with nausea side effects:\")\n",
    "    nausea_results = analyze_side_effects_similarity(\n",
    "        collections, \n",
    "        \"nausea vomiting stomach upset\", \n",
    "        query_model, \n",
    "        3\n",
    "    )\n",
    "    for i, metadata in enumerate(nausea_results['metadatas'][0]):\n",
    "        distance = nausea_results['distances'][0][i]\n",
    "        print(f\"   {i+1}. {metadata['medicine_name']} (similarity: {1-distance:.3f})\")\n",
    "        print(f\"      Composition: {metadata['composition']}\")\n",
    "        print()\n",
    "    \n",
    "    # 4. Top reviewed medicines\n",
    "    print(\"\\n4. ‚≠ê Top reviewed medicines:\")\n",
    "    top_reviewed = get_top_reviewed_medicines(collections, 5)\n",
    "    for i, (id, metadata) in enumerate(top_reviewed):\n",
    "        print(f\"   {i+1}. {metadata['medicine_name']} - Score: {metadata['total_score']}\")\n",
    "        print(f\"      Reviews: {metadata['excellent_review']}% excellent, {metadata['average_review']}% average, {metadata['poor_review']}% poor\")\n",
    "        print()\n",
    "    \n",
    "    # 5. Search by manufacturer\n",
    "    print(\"\\n5. üè≠ Medicines from specific manufacturers:\")\n",
    "    pharma_results = search_similar_medicines(\n",
    "        collections['drugs_main'],\n",
    "        \"Pfizer pharmaceutical company\",\n",
    "        query_model,\n",
    "        3\n",
    "    )\n",
    "    for i, metadata in enumerate(pharma_results['metadatas'][0]):\n",
    "        distance = pharma_results['distances'][0][i]\n",
    "        print(f\"   {i+1}. {metadata['medicine_name']} - {metadata['manufacturer']} (similarity: {1-distance:.3f})\")\n",
    "        print(f\"      Uses: {metadata['uses'][:80]}...\")\n",
    "        print()\n",
    "\n",
    "# Run the demo\n",
    "demo_queries(collections, query_model)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
